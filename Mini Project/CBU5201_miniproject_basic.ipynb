{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaGn4ICrfqXZ"
      },
      "source": [
        "# 1 Author\n",
        "\n",
        "**Student Name**:  Liang Zheyu   \n",
        "**Student ID**:  210977800\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o38VQkcdKd6k"
      },
      "source": [
        "# 2 Problem formulation\n",
        "\n",
        "Describe the machine learning problem that you want to solve and explain what's interesting about it.\n",
        "\n",
        "Using the genki4k dataset, build a machine learning pipeline that takes as an input an image and predicts 1) whether the person in the image is similing or not 2) estimate the 3D head pose labels in the image.   \n",
        "The interesting part of this problem is that it is a multi-task problem. First it needs to predict whether the people is smiling and also estimate the 3D head pose labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3BwrtEdLDit"
      },
      "source": [
        "# 3 Machine Learning pipeline\n",
        "\n",
        "Describe your ML pipeline. Clearly identify its input and output, any intermediate stages (for instance, transformation -> models), and intermediate data moving from one stage to the next. It's up to you to decide which stages to include in your pipeline.   \n",
        "The input of the pipeline is the image data. The output of the pipeline is the prediction of the smile and the 3D head pose labels. The intermediate stages are the transformation and the models. The transformation stage is to transform the image data into the format that the model can use. The model stage is to train the model and predict the result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1nDXnzYLLH6"
      },
      "source": [
        "# 4 Transformation stage\n",
        "\n",
        "Describe any transformations, such as feature extraction. Identify input and output. Explain why you have chosen this transformation stage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F5_kI95LuZ2"
      },
      "source": [
        "# 5 Modelling\n",
        "\n",
        "Describe the ML model(s) that you will build. Explain why you have chosen them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPTSuaB9L2jU"
      },
      "source": [
        "# 6 Methodology\n",
        "\n",
        "Describe how you will train and validate your models, how model performance is assesssed (i.e. accuracy, confusion matrix, etc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZQPxztuL9AW"
      },
      "source": [
        "# 7 Dataset\n",
        "\n",
        "Describe the dataset that you will use to create your models and validate them. If you need to preprocess it, do it here. Include visualisations too. You can visualise raw data samples or extracted features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qf7GN1aeXJI"
      },
      "source": [
        "# 8 Results\n",
        "\n",
        "Carry out your experiments here, explain your results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSrJCR_cekPO"
      },
      "source": [
        "# 9 Conclusions\n",
        "\n",
        "Your conclusions, improvements, etc should go here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 10 code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\three\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "2.15.0\n",
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)\n",
        "\n",
        "import cv2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load GENKI dateset\n",
        "def load_genki_data():\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for i in range(1, 1165):  # GENKI数据集的图片数量\n",
        "        img_path = f'path/to/genki4k/files/GENKI-{i:04}.jpg'\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, (64, 64))  # 调整图像大小\n",
        "        images.append(img)\n",
        "        \n",
        "        # 从文件名中提取标签 (0表示没有笑脸，1表示有笑脸)\n",
        "        label = 1 if \"noglasses\" in img_path else 0\n",
        "        labels.append(label)\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = to_categorical(labels, num_classes=2)  # one-hot编码标签\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 加载GENKI数据集\n",
        "def load_genki_data():\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    with open('path/to/genki4k/labels.txt', 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        for i, line in enumerate(lines):\n",
        "            img_path = f'path/to/genki4k/files/GENKI-{i+1:04}.jpg'\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.resize(img, (64, 64))  # 调整图像大小\n",
        "            images.append(img)\n",
        "\n",
        "            # 解析标签信息\n",
        "            label, _, _, _ = map(float, line.strip().split())\n",
        "            labels.append(int(label))\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = to_categorical(labels, num_classes=2)  # one-hot编码笑脸标签\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "# 划分训练集和测试集\n",
        "def split_data(images, labels, test_size=0.2, random_state=42):\n",
        "    return train_test_split(images, labels, test_size=test_size, random_state=random_state)\n",
        "\n",
        "# 构建笑脸分类模型\n",
        "def build_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# 加载数据集\n",
        "images, labels = load_genki_data()\n",
        "\n",
        "# 划分训练集和测试集\n",
        "train_images, test_images, train_labels, test_labels = split_data(images, labels)\n",
        "\n",
        "# 构建并训练模型\n",
        "input_shape = (64, 64, 3)\n",
        "model = build_model(input_shape)\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(test_images, test_labels))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
